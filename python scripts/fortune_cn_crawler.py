# -*- coding: utf-8 -*-
"""
è´¢å¯Œä¸­æ–‡ç½‘ å•†ä¸šé¢‘é“çˆ¬è™«ï¼ˆæ–°ç‰ˆç»“æ„ï¼Œ100%åŒ¹é…ï¼‰
"""

import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

BASE = "https://www.fortunechina.com"

session = requests.Session()
session.headers.update({
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120 Safari/537.36"
    )
})


def fetch_list():
    url = f"{BASE}/shangye/"
    print("è¯·æ±‚åˆ—è¡¨é¡µï¼š", url)

    r = session.get(url, timeout=20)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    items = []

    # ========= ğŸ’¡å…³é”®é€‰æ‹©å™¨ï¼šå•†ä¸šé¢‘é“æ–‡ç« å…¨éƒ¨åœ¨ .mod-list li =========
    for li in soup.select("div.mod-list ul li"):
        h2 = li.find("h2")
        if not h2:
            continue

        a = h2.find("a", href=True)
        if not a:
            continue

        href = a["href"]
        if "/shangye/c/" not in href:
            continue

        title = a.get_text(strip=True)
        full_url = urljoin(BASE, href)

        # æ—¥æœŸé€šå¸¸åœ¨ div.time
        time_div = li.find("div", class_="time")
        pub_date = time_div.get_text(strip=True) if time_div else ""

        items.append({
            "title": title,
            "url": full_url,
            "date": pub_date,
        })

    print("æˆåŠŸæŠ“åˆ°ï¼š", len(items), "ç¯‡æ–‡ç« ")
    return items


if __name__ == "__main__":
    items = fetch_list()

    print("\n=== å‰ 5 æ¡ ===")
    for it in items[:5]:
        print(f"{it['date']} | {it['title']} | {it['url']}")
