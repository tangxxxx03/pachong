name: Daily HR + Fortune China 合并爬虫

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 1 * * 1-5"   # 周一到周五，北京时间 09:00（GitHub 用 UTC）

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      # —— AI —— 
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      AI_API_BASE: "https://api.siliconflow.cn/v1"
      AI_MODEL: "Qwen/Qwen2.5-7B-Instruct"

      # —— 钉钉推送：单个群聊机器人 —— 
      DINGTALK_BASES:   ${{ secrets.SHIYANQUNWEBHOOK }}
      DINGTALK_SECRETS: ${{ secrets.SHIYANQUNSECRET }}

      # —— 可选日期控制（为空则按默认：三茅=当天，财富=昨天） —— 
      HR_TARGET_DATE: ""
      TARGET_DATE: ""

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Combined Crawler (HR + FortuneChina)
        run: |
          python daily_news_combo.py
