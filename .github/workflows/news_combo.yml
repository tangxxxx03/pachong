name: Daily HR + Fortune China 合并爬虫

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 1 * * 1-5"

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      # —— AI —— 
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      AI_API_BASE: "https://api.siliconflow.cn/v1"
      AI_MODEL: "Qwen/Qwen2.5-7B-Instruct"

      # —— 钉钉推送：两个群聊机器人（用英文逗号隔开）——
      DINGTALK_BASES: >
        ${{ secrets.DINGDINGSHANGYEWEBHOOK }},
        ${{ secrets.dingdingxiaoqunwebhook }}

      DINGTALK_SECRETS: >
        ${{ secrets.DINGDINGSHANGYESECRET }},
        ${{ secrets.dingdingxiaoqunsecret }}

      # —— 可选日期控制 —— 
      HR_TARGET_DATE: ""
      TARGET_DATE: ""

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run Combined Crawler (HR + FortuneChina)
        run: |
          python daily_news_combo.py
