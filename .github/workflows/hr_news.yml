name: HR News Crawler

on:
  workflow_dispatch: {}
  # 每天 08:00（Asia/Shanghai）运行；UTC=00:00
  schedule:
    - cron: '0 0 * * *'

jobs:
  crawl:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai
      # 如需你自己的钉钉，可用仓库 Secrets：
      # DINGTALK_BASE: ${{ secrets.DINGTALK_BASE }}
      # DINGTALK_SECRET: ${{ secrets.DINGTALK_SECRET }}

    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Setup Python 3.10"
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: "Upgrade pip"
        run: python -m pip install -U pip

      - name: "Install dependencies"
        run: if [ -f requirements.txt ]; then pip install -r requirements.txt; else pip install requests beautifulsoup4 urllib3 backports.zoneinfo; fi

      - name: "Run crawler - both"
        run: python hr_news_crawler.py both --keywords '外包,人力资源,派遣' --pages 2 --window-hours 24 --limit 12

      - name: "Upload CSV results"
        uses: actions/upload-artifact@v4
        with:
          name: csv-results-${{ github.run_id }}
          path: '*.csv'
          if-no-files-found: ignore

      - name: "Upload JSON results"
        uses: actions/upload-artifact@v4
        with:
          name: json-results-${{ github.run_id }}
          path: '*.json'
          if-no-files-found: ignore
