name: HR News Crawler

on:
  workflow_dispatch:
  # 每天 08:00（Asia/Shanghai）运行；UTC=00:00
  schedule:
    - cron: '0 0 * * *'

jobs:
  crawl:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai
      # 如需你自己的钉钉机器人，建议用仓库 Secrets 配置：
      # DINGTALK_BASE: ${{ secrets.DINGTALK_BASE }}
      # DINGTALK_SECRET: ${{ secrets.DINGTALK_SECRET }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Upgrade pip
        run: python -m pip install -U pip

      - name: Install dependencies
        shell: bash
        run: if [ -f requirements.txt ]; then pip install -r requirements.txt; else pip install requests beautifulsoup4 urllib3 backports.zoneinfo; fi

      - name: Run crawler (both: People.cn + HR)
        run: python hr_news_crawler.py both --keywords '外包,人力资源,派遣' --pages 2 --window-hours 24 --limit 12

      - name: Upload results (CSV/JSON)
        uses: actions/upload-artifact@v4
        with:
          name: news-results-${{ github.run_id }}
          path: |
            *.csv
            *.json
          if-no-files-found: ignore
