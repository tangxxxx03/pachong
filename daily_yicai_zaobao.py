# -*- coding: utf-8 -*-
import os
import re
import time
import hmac
import base64
import hashlib
import requests
import feedparser
from html import unescape
from datetime import datetime, timezone, timedelta

# ================= é…ç½®éƒ¨åˆ† =================
RSS_URLS = [
    "https://rsshub.rssforever.com/yicai/feed/669",
    "https://rss.imgony.com/yicai/feed/669",
    "https://rsshub.ktachibana.party/yicai/feed/669",
    "https://rss.shab.fun/yicai/feed/669",
    "https://rsshub.app/yicai/feed/669",
]

UA = "Mozilla/5.0 (GitHubActions)"
TIMEOUT = 45 

# å®šä¹‰åŒ—äº¬æ—¶åŒº (UTC+8)
TZ_CN = timezone(timedelta(hours=8))
# ===========================================

def fetch_feed():
    for url in RSS_URLS:
        try:
            print(f"Trying to fetch: {url}")
            r = requests.get(url, timeout=TIMEOUT, headers={"User-Agent": UA})
            r.raise_for_status()
            feed = feedparser.parse(r.text)
            
            if feed.entries:
                print(f"[RSS] Success via {url}, entries count: {len(feed.entries)}")
                return feed
            else:
                print(f"[RSS] Parsed empty content via {url}, trying next...")
                
        except Exception as e:
            print(f"[RSS] Failed: {url} -> {e}")

    print("[RSS] All sources unavailable")
    return None


def extract_numbered_titles(description):
    """
    ä»æè¿°æ–‡æœ¬ä¸­æå–å¸¦ç¼–å·çš„æ ‡é¢˜ã€‚
    """
    if not description:
        return []

    text = unescape(description)
    
    # æ›¿æ¢ HTML æ¢è¡Œç¬¦
    text = re.sub(r"<br\s*/?>", "\n", text, flags=re.IGNORECASE)
    text = re.sub(r"</p>", "\n", text, flags=re.IGNORECASE)
    
    # ç§»é™¤ HTML æ ‡ç­¾
    text = re.sub(r"<[^>]+>", "", text)

    titles = []
    for line in text.splitlines():
        line = line.strip()
        # åŒ¹é… "1. xxx" æˆ– "1ã€xxx"
        if re.match(r"^\d+[\.ã€]\s*.+", line):
            clean_title = re.sub(r"^\d+[\.ã€]\s*", "", line)
            titles.append(clean_title)

    return titles


def parse_zaobao_titles(entries):
    """
    ç²¾å‡†æŸ¥æ‰¾ã€ä»Šå¤©ã€‘å‘å¸ƒçš„ã€ä¸”æ ‡é¢˜åŒ…å«ã€æ—©æŠ¥ã€‘çš„æ–‡ç« 
    """
    today_cn = datetime.now(TZ_CN).date()
    print(f"DEBUG: Target Date (Beijing) = {today_cn}")

    target_entry = None

    # 1. ä¼˜å…ˆå¯»æ‰¾æ ‡é¢˜é‡Œå¸¦æœ‰ "æ—©æŠ¥" ä¸”æ˜¯ä»Šå¤©çš„æ–‡ç« 
    for e in entries:
        title = e.get("title", "No Title")
        
        if not hasattr(e, "published_parsed") or not e.published_parsed:
            continue
        
        # æ—¶é—´è½¬æ¢
        dt_utc = datetime(*e.published_parsed[:6], tzinfo=timezone.utc)
        dt_cn = dt_utc.astimezone(TZ_CN)
        pub_date_cn = dt_cn.date()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ä»Šå¤©
        if pub_date_cn == today_cn:
            # æ£€æŸ¥æ ‡é¢˜å…³é”®å­—
            if "æ—©æŠ¥" in title:
                print(f"DEBUG: Found 'ZaoBao' article: [{title}]")
                target_entry = e
                break # æ‰¾åˆ°äº†å°±åœæ­¢
            else:
                # è®°å½•ä¸€ä¸‹æ‰¾åˆ°äº†åˆ«çš„æ–‡ç« ï¼Œæ–¹ä¾¿è°ƒè¯•
                print(f"DEBUG: Skipped regular news: [{title}]")

    # 2. å¦‚æœä»Šå¤©æ²¡æ‰¾åˆ°å¸¦â€œæ—©æŠ¥â€çš„ï¼Œå°è¯•å›é€€ä¸€å¤©ï¼ˆé˜²æ­¢æ—¶åŒºè¾¹ç¼˜æˆ–å‘å¸ƒå»¶è¿Ÿï¼‰
    if not target_entry:
        print("DEBUG: No 'ZaoBao' found for today, checking yesterday...")
        yesterday_cn = today_cn - timedelta(days=1)
        for e in entries:
            title = e.get("title", "")
            if "æ—©æŠ¥" in title:
                dt_utc = datetime(*e.published_parsed[:6], tzinfo=timezone.utc)
                if dt_utc.astimezone(TZ_CN).date() == yesterday_cn:
                    print(f"DEBUG: Found yesterday's 'ZaoBao' instead: [{title}]")
                    target_entry = e
                    break

    # 3. å¼€å§‹è§£æ
    if target_entry:
        return extract_numbered_titles(target_entry.get("description", ""))
    else:
        print("DEBUG: No 'ZaoBao' article found in recent feed.")
        return []


def sign(timestamp, secret):
    string_to_sign = f"{timestamp}\n{secret}"
    h = hmac.new(secret.encode(), string_to_sign.encode(), hashlib.sha256).digest()
    return base64.b64encode(h).decode()


def send_dingtalk(text):
    webhook = os.getenv("DINGTALK_WEBHOOK")
    secret = os.getenv("DINGTALK_SECRET")

    if not webhook or not secret:
        print("DingTalk not configured, skip send")
        return

    ts = str(round(time.time() * 1000))
    url = f"{webhook}&timestamp={ts}&sign={sign(ts, secret)}"

    payload = {
        "msgtype": "text",
        "text": {"content": text}
    }

    try:
        requests.post(url, json=payload, timeout=10).raise_for_status()
        print("DingTalk send success")
    except Exception as e:
        print(f"DingTalk send failed: {e}")


def main():
    feed = fetch_feed()
    if not feed:
        return

    titles = parse_zaobao_titles(feed.entries)
    
    if not titles:
        print("Error: Could not extract points from ZaoBao.")
        return

    # ç”Ÿæˆæœ€ç»ˆæ–‡æ¡ˆ
    today_str = datetime.now(TZ_CN).strftime("%Y-%m-%d")
    lines = [f"ğŸ“° ä¸€è´¢æ—©æŠ¥ï¼ˆ{today_str}ï¼‰â€” è¦ç‚¹é€Ÿè§ˆ\n"]

    for i, t in enumerate(titles, 1):
        lines.append(f"{i}. {t}")

    final_text = "\n".join(lines)
    send_dingtalk(final_text)


if __name__ == "__main__":
    main()
