# -*- coding: utf-8 -*-
"""
ä¸‰èŒ…ç½‘ + è´¢å¯Œä¸­æ–‡ç½‘ åˆå¹¶çˆ¬è™« V25 (å®Œç¾è“å­—ç‰ˆ) + AIé—¸é—¨ç‰ˆ
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
æ ¸å¿ƒæ›´æ–°ï¼š
1. æ’ç‰ˆå›å½’ V23ï¼ˆEmoji + åºå·ï¼‰ï¼Œç»“æ„æ¸…æ™°ã€‚
2. é“¾æ¥ä¼˜åŒ–ï¼šæ ‡é¢˜ç›´æ¥å˜è“å­—é“¾æ¥ï¼Œç‚¹å‡»å³è·³ï¼Œæ— åç¼€å›¾æ ‡ã€‚
3. âœ… æ–°å¢ AI é—¸é—¨ï¼šå¦‚æœ token/ä½™é¢/é…é¢ç”¨å°½ï¼Œåˆ™ä¸å‘é€é’‰é’‰ï¼ˆç”¨äºâ€œæ²¡æ”¶åˆ°å°±çŸ¥é“è¯¥ç»­è´¹â€ï¼‰

ç¯å¢ƒå˜é‡ï¼š
- OPENAI_API_KEY / AI_API_KEYï¼ˆå…¼å®¹ï¼‰
- AI_API_BASEï¼ˆé»˜è®¤ https://api.siliconflow.cn/v1ï¼‰
- AI_MODELï¼ˆé»˜è®¤ Qwen/Qwen2.5-7B-Instructï¼‰
- AI_GATE_ENABLEï¼š1=å¼€å¯é—¸é—¨(é»˜è®¤)ï¼›0=å…³é—­é—¸é—¨
"""

import os
import re
import ssl
import sys
import time
import hmac
import base64
import hashlib
import urllib.parse
from datetime import datetime, date
from urllib.parse import urljoin, quote

import requests
from bs4 import BeautifulSoup, Tag
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

# --- AI ä¾èµ– ---
try:
    from openai import OpenAI
    HAS_OPENAI_LIB = True
except ImportError:
    HAS_OPENAI_LIB = False

try:
    from zoneinfo import ZoneInfo
except:
    from backports.zoneinfo import ZoneInfo


# ================== åŸºç¡€å·¥å…· ==================

def _tz():
    return ZoneInfo("Asia/Shanghai")

def now_tz():
    return datetime.now(_tz())

def norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def zh_weekday(dt: datetime) -> str:
    return ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][dt.weekday()]

def safe_url(url: str) -> str:
    if not url: return ""
    return quote(url.strip(), safe=":/?&amp;=#%")


# ================== AI æ€»ç»“æ¨¡å—ï¼ˆå«é—¸é—¨ï¼‰ ==================

AI_API_KEY = (os.getenv("OPENAI_API_KEY", "") or os.getenv("AI_API_KEY", "")).strip()
AI_API_BASE = os.getenv("AI_API_BASE", "https://api.siliconflow.cn/v1").rstrip("/")
AI_MODEL = os.getenv("AI_MODEL", "Qwen/Qwen2.5-7B-Instruct")

AI_GATE_ENABLE = (os.getenv("AI_GATE_ENABLE", "1") or "1").strip()  # 1=å¼€å¯ï¼Œ0=å…³é—­

AI_CLIENT = None
if HAS_OPENAI_LIB and AI_API_KEY:
    try:
        AI_CLIENT = OpenAI(api_key=AI_API_KEY, base_url=AI_API_BASE)
    except:
        AI_CLIENT = None

# é—¸é—¨çŠ¶æ€ï¼šä¸€æ—¦è§¦å‘ï¼Œå°±ä¸å‘é’‰é’‰
AI_GATE_TRIPPED = False
AI_GATE_REASON = ""

def _extract_status_code(e) -> int:
    # openai æ–°ç‰ˆå¼‚å¸¸ä¸€èˆ¬å¸¦ status_codeï¼›æ²¡æœ‰å°±è¿”å› 0
    try:
        sc = getattr(e, "status_code", None)
        if isinstance(sc, int):
            return sc
    except:
        pass
    return 0

def _is_quota_or_token_error(e) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦å±äºâ€œtoken/ä½™é¢/é…é¢/é™æµâ€ç±»é”™è¯¯
    è§„åˆ™ï¼šHTTP 401/402/429 æˆ–æ–‡æœ¬å‘½ä¸­å…³é”®è¯
    """
    sc = _extract_status_code(e)
    if sc in (401, 402, 429):
        return True

    msg = (str(e) or "").lower()
    keywords = [
        "insufficient_quota",
        "quota",
        "rate limit",
        "rate_limit",
        "exceeded",
        "payment",
        "ä½™é¢",
        "æ¬ è´¹",
        "å……å€¼",
        "é…é¢",
        "é™æµ",
        "è¶…å‡º",
        "ç”¨å®Œ",
        "ä¸è¶³",
    ]
    return any(k in msg for k in keywords)

def _trip_ai_gate(reason: str):
    global AI_GATE_TRIPPED, AI_GATE_REASON
    AI_GATE_TRIPPED = True
    AI_GATE_REASON = reason or "AI é¢åº¦/é…é¢å¼‚å¸¸"
    print(f"ğŸ§¯ AIé—¸é—¨è§¦å‘ï¼š{AI_GATE_REASON}")

def ai_healthcheck():
    """
    ä¸»åŠ¨æ¢æµ‹ï¼ˆ1 tokenï¼‰ï¼Œæ›´æ—©å‘ç°â€œç”¨å…‰äº†â€
    - é—¸é—¨å…³é—­ï¼šç›´æ¥è·³è¿‡
    - AI æœªé…ç½®ï¼šå¦‚æœé—¸é—¨å¼€ç€ï¼Œåˆ™è®¤ä¸ºä¸å®‰å…¨ -> è§¦å‘é—¸é—¨ï¼ˆè®©ä½ åŠæ—¶è¡¥é…ç½®/ç»­è´¹ï¼‰
    """
    if AI_GATE_ENABLE != "1":
        print("ğŸ”• AIé—¸é—¨å·²å…³é—­ï¼ˆAI_GATE_ENABLE=0ï¼‰ï¼Œè·³è¿‡æ¢æµ‹ã€‚")
        return

    if not AI_CLIENT:
        _trip_ai_gate("AIé—¸é—¨å¼€å¯ï¼Œä½†æœªé…ç½®å¯ç”¨çš„ AI_CLIENTï¼ˆç¼º KEY æˆ– openai åº“ä¸å¯ç”¨ï¼‰")
        return

    try:
        AI_CLIENT.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": "healthcheck"},
                {"role": "user", "content": "ping"}
            ],
            max_tokens=1,
            temperature=0
        )
        print("âœ… AIé—¸é—¨æ¢æµ‹é€šè¿‡ï¼šé¢åº¦å¯ç”¨")
    except Exception as e:
        if _is_quota_or_token_error(e):
            _trip_ai_gate(f"AIé¢åº¦/é…é¢ç–‘ä¼¼ç”¨å°½ï¼š{str(e)[:200]}")
        else:
            # å…¶å®ƒå¼‚å¸¸ä¹Ÿæ‹¦ï¼ˆå®å¯ä¸å‘ï¼Œä¹Ÿä¸è¦è¯¯ä»¥ä¸ºæ­£å¸¸ï¼‰
            _trip_ai_gate(f"AIè°ƒç”¨å¼‚å¸¸ï¼ˆéé…é¢ä½†ä¸ç¨³å®šï¼‰ï¼š{str(e)[:200]}")

def get_ai_summary(content: str, title: str = "") -> str:
    """30å­—æé™æ€»ç»“ï¼ˆè‹¥é—¸é—¨è§¦å‘ï¼Œåˆ™ç›´æ¥è¿”å›æ ‡é¢˜ï¼›å¹¶åœæ­¢åç»­å·¥ä½œç”±ä¸Šå±‚å¤„ç†ï¼‰"""
    if not AI_CLIENT:
        return title
    if AI_GATE_TRIPPED:
        return title
    if not content or len(content) < 50:
        return title

    print(f"  ğŸ¤– æ­£åœ¨ AI æ€»ç»“: {title[:10]}...")

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæç®€å¿«è®¯ç¼–è¾‘ã€‚è¯·å°†æ–°é—»å‹ç¼©ä¸ºä¸€å¥**30å­—ä»¥å†…**çš„çŸ­è¯­ã€‚\n"
        "è§„åˆ™ï¼š1.å­—æ•°é”æ­»30å­—å†…ã€‚2.å»åºŸè¯ï¼Œç›´æ¥è¯´ç»“è®ºã€‚3.ç¦æ­¢ä»»ä½•æ ‡ç­¾ã€‚"
    )
    user_prompt = f"æ ‡é¢˜ï¼š{title}\næ­£æ–‡ï¼š{content[:2000]}"

    try:
        resp = AI_CLIENT.chat.completions.create(
            model=AI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=60,
            temperature=0.3
        )
        summary = resp.choices[0].message.content.strip()
        summary = summary.replace('"', '').replace("'", "").replace("\n", " ")
        summary = re.sub(r"^(æ‘˜è¦|ç»“è®º|æ ¸å¿ƒ|èƒŒæ™¯)[/:]\s*", "", summary)

        if "åŸæ ‡é¢˜" in summary and len(summary) < 10:
            return title

        print(f"  âœ¨ æ‘˜è¦æˆåŠŸ: {summary[:20]}...")
        return summary
    except Exception as e:
        # å¦‚æœæ˜¯é¢åº¦/é…é¢é—®é¢˜ï¼šè§¦å‘é—¸é—¨ï¼Œåç»­ä¸å‘é’‰é’‰
        if _is_quota_or_token_error(e):
            _trip_ai_gate(f"AIé¢åº¦/é…é¢ç”¨å°½æˆ–é™æµï¼š{str(e)[:200]}")
        else:
            # å…¶å®ƒå¼‚å¸¸ï¼šä¹Ÿè§¦å‘é—¸é—¨ï¼Œé¿å…ä½ ä»¥ä¸ºä»Šå¤©æ­£å¸¸æ¨é€
            _trip_ai_gate(f"AIè°ƒç”¨å¼‚å¸¸ï¼š{str(e)[:200]}")
        return title


# ================== HTTP Session ==================

class LegacyTLSAdapter(HTTPAdapter):
    def init_poolmanager(self, *a, **kw):
        ctx = ssl.create_default_context()
        if hasattr(ssl, "OP_LEGACY_SERVER_CONNECT"):
            ctx.options |= ssl.OP_LEGACY_SERVER_CONNECT
        kw["ssl_context"] = ctx
        return super().init_poolmanager(*a, **kw)

def make_session() -> requests.Session:
    s = requests.Session()
    s.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
        "Accept-Language": "zh-CN,zh;q=0.9",
    })
    r = Retry(total=3, backoff_factor=0.6, status_forcelist=[500, 502, 503, 504])
    s.mount("https://", LegacyTLSAdapter(max_retries=r))
    return s


# ================== ä¸‰èŒ…æ—¥æŠ¥çˆ¬è™« ==================

class HRLooCrawler:
    def __init__(self):
        self.session = make_session()
        self.results = []
        self.target_date = now_tz().date()
        t = os.getenv("HR_TARGET_DATE", "")
        if t:
            try:
                y, m, d = map(int, t.split("-"))
                self.target_date = date(y, m, d)
            except: pass
        self.sources = ["https://www.hrloo.com/", "https://www.hrloo.com/news/hr"]
        self.daily_title_pat = re.compile(r"ä¸‰èŒ…æ—¥[æŠ¥å ±]")

    def run(self):
        for base in self.sources:
            if self._crawl_source(base): break

    def _crawl_source(self, base):
        try:
            r = self.session.get(base, timeout=15)
            r.encoding = "utf-8"
            if r.status_code != 200: return False
            soup = BeautifulSoup(r.text, "html.parser")

            items = soup.select("div.dwxfd-list-items div.dwxfd-list-content-left")
            if items:
                for div in items:
                    dts = (div.get("dwdata-time") or "").strip()
                    if dts and str(self.target_date) not in dts: continue
                    a = div.find("a", href=True)
                    if not a: continue
                    if self._check_and_fetch(base, a): return True

            for a in soup.select("a[href*='/news/']"):
                if self._check_and_fetch(base, a): return True
        except: pass
        return False

    def _check_and_fetch(self, base, a):
        text = norm(a.get_text())
        href = a["href"]
        if not self.daily_title_pat.search(text): return False
        abs_url = urljoin(base, href)
        return self._fetch_detail(abs_url)

    def _fetch_detail(self, url):
        try:
            r = self.session.get(url, timeout=15)
            r.encoding = "utf-8"
            soup = BeautifulSoup(r.text, "html.parser")
            container = soup.select_one(".content-con.hr-rich-text") or soup
            titles = []
            for st in container.select("strong"):
                t = norm(st.get_text())
                t = re.sub(r"^\d+[.ã€]\s*", "", t)
                if len(t) > 5 and "é˜…è¯»" not in t:
                    titles.append(t)
            if not titles:
                for p in container.select("p"):
                    t = norm(p.get_text())
                    if re.match(r"^\d+[.ã€]", t) and len(t) > 5:
                        titles.append(re.sub(r"^\d+[.ã€]\s*", "", t))
            titles = list(dict.fromkeys(titles))

            if titles:
                self.results.append({
                    "title": "ä¸‰èŒ…æ—¥æŠ¥",
                    "url": safe_url(url),
                    "titles": titles
                })
                return True
        except: pass
        return False

def build_hr_md(crawler):
    if not crawler.results: return "> ä»Šæ—¥ä¸‰èŒ…æš‚æ— æ›´æ–°ã€‚\n"
    it = crawler.results[0]
    md = [f"**ğŸ“° äººåŠ›èµ„è®¯**"]
    for i, t in enumerate(it['titles'], 1):
        md.append(f"{i}. [{t}]({it['url']})")
    return "\n".join(md) + "\n"


# ================== è´¢å¯Œä¸­æ–‡ç½‘çˆ¬è™« ==================

BASE_FORTUNE = "https://www.fortunechina.com"
LIST_URL = "https://www.fortunechina.com/shangye/"

class FortuneCrawler:
    def __init__(self, max_items=5):
        self.session = make_session()
        self.max_items = max_items
        self.items = []

    def run(self):
        print(f"[Fortune] å¼€å§‹æŠ“å–...")
        try:
            r = self.session.get(LIST_URL, timeout=15)
            r.encoding = "utf-8"
            soup = BeautifulSoup(r.text, "html.parser")

            cnt = 0
            for li in soup.select("ul.news-list li.news-item"):
                if cnt >= self.max_items: break
                if AI_GATE_TRIPPED:  # é—¸é—¨è§¦å‘å°±ä¸ç»§ç»­çƒ§è¯·æ±‚äº†
                    break

                h2 = li.find("h2")
                a = li.find("a", href=True)

                if not (h2 and a): continue

                href = a["href"].strip()
                if "content_" not in href: continue

                title = norm(h2.get_text())
                full_url = urljoin(LIST_URL, href)

                content = self._fetch_content(full_url)
                ai_summary = get_ai_summary(content, title)

                self.items.append({
                    "title": title,
                    "summary": ai_summary,
                    "url": safe_url(full_url)
                })
                cnt += 1

        except Exception as e:
            print(f"[Fortune Error] {e}")

    def _fetch_content(self, url):
        try:
            r = self.session.get(url, timeout=10)
            r.encoding = "utf-8"
            soup = BeautifulSoup(r.text, "html.parser")
            container = soup.select_one("div.article-mod div.word-text-con") or \
                        soup.select_one("div.article-content")

            if container: return norm(container.get_text())
        except: pass
        return ""

def build_fortune_md(crawler):
    if not crawler.items: return "> ä»Šæ—¥è´¢å¯Œæš‚æ— æ›´æ–°ã€‚\n"
    md = ["**ğŸš€ è´¢å¯Œå•†ä¸š**"]
    for i, it in enumerate(crawler.items, 1):
        display_text = it['summary']
        md.append(f"{i}. [{display_text}]({it['url']})")
    return "\n".join(md) + "\n"


# ================== æ¨é€ä¸å…¥å£ ==================

def send_dingtalk(title, text):
    bases = (os.getenv("DINGTALK_BASES") or "").split(",")
    secrets = (os.getenv("DINGTALK_SECRETS") or "").split(",")

    if not bases or not bases[0]:
        print("ğŸ”• æœªé…ç½® DINGTALK_BASES")
        return

    for i, base in enumerate(bases):
        base = base.strip()
        if not base: continue
        secret = secrets[i].strip() if i < len(secrets) else ""

        if secret:
            ts = str(round(time.time() * 1000))
            s = f"{ts}\n{secret}".encode("utf-8")
            sign = urllib.parse.quote_plus(base64.b64encode(hmac.new(secret.encode("utf-8"), s, hashlib.sha256).digest()))
            url = f"{base}&timestamp={ts}&sign={sign}"
        else:
            url = base

        try:
            requests.post(url, json={
                "msgtype": "markdown",
                "markdown": {"title": title, "text": text}
            }, timeout=10)
            print(f"âœ… æ¨é€æˆåŠŸ: æœºå™¨äºº {i+1}")
        except Exception as e:
            print(f"âŒ æ¨é€å¤±è´¥: {e}")

def main():
    print("=== å¯åŠ¨åˆå¹¶çˆ¬è™« V25 (è“å­—ç‰ˆ + AIé—¸é—¨) ===")

    # 0) AI é—¸é—¨æ¢æµ‹ï¼ˆå…ˆæ¢æµ‹ï¼Œé¿å…æŠ“å®Œå†å‘ç°ç”¨ä¸äº†ï¼‰
    ai_healthcheck()

    # å¦‚æœé—¸é—¨è§¦å‘ï¼šä¸å‘é’‰é’‰ï¼Œç›´æ¥é€€å‡ºï¼ˆè®©ä½ ç«‹åˆ»çŸ¥é“è¯¥ç»­è´¹/ä¿®é…ç½®ï¼‰
    if AI_GATE_TRIPPED:
        print("ğŸš« å›  AI é—¸é—¨è§¦å‘ï¼Œæœ¬æ¬¡ä¸å‘é€é’‰é’‰æ¶ˆæ¯ã€‚")
        print(f"åŸå› ï¼š{AI_GATE_REASON}")
        sys.exit(2)

    # 1) ä¸‰èŒ…
    hr = HRLooCrawler()
    hr.run()
    hr_md = build_hr_md(hr)

    # 2) è´¢å¯Œ
    fc = FortuneCrawler(max_items=int(os.getenv("FORTUNE_MAX_ITEMS") or 5))
    fc.run()

    # å¦‚æœåœ¨è´¢å¯ŒæŠ“å–/AIæ€»ç»“è¿‡ç¨‹ä¸­è§¦å‘é—¸é—¨ï¼šä¹Ÿä¸å‘é’‰é’‰
    if AI_GATE_TRIPPED:
        print("ğŸš« æŠ“å–è¿‡ç¨‹ä¸­è§¦å‘ AI é—¸é—¨ï¼Œæœ¬æ¬¡ä¸å‘é€é’‰é’‰æ¶ˆæ¯ã€‚")
        print(f"åŸå› ï¼š{AI_GATE_REASON}")
        sys.exit(2)

    fc_md = build_fortune_md(fc)

    # 3) åˆå¹¶
    final_md = (
        f"**ğŸ“… {now_tz().strftime('%m-%d')} æ¯æ—¥æ—©æŠ¥** \n\n"
        f"{hr_md}\n"
        f"{fc_md}"
    )

    print("\n--- Markdown é¢„è§ˆ ---\n")
    print(final_md)

    send_dingtalk("æ¯æ—¥æ—©æŠ¥", final_md)

if __name__ == "__main__":
    main()
